{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T04:53:00.636656Z",
     "iopub.status.busy": "2025-11-20T04:53:00.635974Z",
     "iopub.status.idle": "2025-11-20T04:53:00.672672Z",
     "shell.execute_reply": "2025-11-20T04:53:00.672063Z",
     "shell.execute_reply.started": "2025-11-20T04:53:00.636635Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import pickle,json,math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.serialization\n",
    "torch.serialization.add_safe_globals([np.core.multiarray._reconstruct])\n",
    "L=[]\n",
    "# ‚úîÔ∏è\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"Êà™Êñ≠ÊàñËÄÖÂ°´ÂÖÖÂ∫èÂàó,‰ª•‰øùËØÅÂ∫èÂàóÈïøÂ∫¶‰∏ÄËá¥\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]\n",
    "    return line + [padding_token] * (num_steps - len(line))\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "class FFN(nn.Module):\n",
    "    \"\"\"\n",
    "    Âü∫‰∫é‰ΩçÁΩÆÁöÑÂâçÈ¶àÁΩëÁªú,‰ªÖÊîπÂèòËæìÂÖ•ÁöÑÊúÄÂêé‰∏Ä‰∏™Áª¥Â∫¶\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ffn_num_inputs, ffn_num_hiddens, ffn_num_outputs, **kwargs):\n",
    "        super(FFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_inputs, ffn_num_hiddens)\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))\n",
    "\n",
    "#‚úîÔ∏è\n",
    "class AddNorm(nn.Module):\n",
    "    \"\"\"Â±ÇÂΩí‰∏ÄÂåñ\"\"\"\n",
    "\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.LN = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, y):\n",
    "        return self.LN(self.dropout(y) + X)\n",
    "\n",
    "#‚úîÔ∏è\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32, device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"\n",
    "    ÊúâÊé©Á†ÅÁöÑ softmax,‰ª•Ê∂àÈô§padÊàñËÄÖÊó†ÂÖ≥Âõ†Á¥†ÁöÑÂΩ±Âìç\n",
    "    \"\"\"\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        X = sequence_mask(X.reshape(-1, X.shape[-1]), valid_lens, value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"Âä†ÊÄßÊ≥®ÊÑèÂäõ\"\"\"\n",
    "\n",
    "    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n",
    "        super(AdditiveAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        self.W_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        quaries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        features = quaries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        scores = self.W_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"Áº©ÊîæÁÇπÁßØÊ≥®ÊÑèÂäõ\"\"\"\n",
    "\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        dim = queries.shape[-1]\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(dim)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"transform shape\"\"\"\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"ÂèçÂèòÊç¢\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "def grad_clipping(net, theta):\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "    norm = torch.sqrt(sum(torch.sum(p.grad ** 2) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "class Accumulator():\n",
    "    def __init__(self, num):\n",
    "        self.Record = [0] * num\n",
    "\n",
    "    def add(self, *args):\n",
    "        if args:\n",
    "            for i in range(len(args)):\n",
    "                self.Record[i] += args[i]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.Record[idx]\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\"Â§öÂ§¥Ê≥®ÊÑèÂäõ\"\"\"\n",
    "\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, repeats=self.num_heads, dim=0)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "        output = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output)\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # È¢ÑËÆ°ÁÆóÊâÄÊúâÂèØËÉΩÁöÑ‰ΩçÁΩÆÁºñÁ†Å\n",
    "        P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(-1, 1) / torch.pow(\n",
    "            10000, torch.arange(0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        P[:, :, 0::2] = torch.sin(X)\n",
    "        P[:, :, 1::2] = torch.cos(X)\n",
    "        self.register_buffer('P', P)   # ‰∏çÂèÇ‰∏éÊ¢ØÂ∫¶Ôºå‰ΩÜ‰ºöÈöèÊ®°Âûã‰øùÂ≠ò\n",
    "\n",
    "    def forward(self, X, offset=0):\n",
    "        \"\"\"\n",
    "        X: (batch_size, seq_len, num_hiddens)\n",
    "        offset: ÂΩìÂâçËß£Á†ÅÊ≠•ÁöÑËµ∑Âßã‰ΩçÁΩÆÔºàËÆ≠ÁªÉÊó∂=0ÔºåÈ¢ÑÊµãÊó∂=0,1,2,...Ôºâ\n",
    "        \"\"\"\n",
    "        X = X + self.P[:, offset:offset + X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "class MaskedSoftmaxLoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"\n",
    "    Â∏¶ÈÅÆËîΩÁöÑsoftmax‰∫§ÂèâÁÜµÊçüÂ§±ÂáΩÊï∞\n",
    "    \"\"\"\n",
    "    def forward(self, pred, label, valid_lens):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_lens)\n",
    "        self.reduction = \"none\"\n",
    "        unweighted_loss = super(MaskedSoftmaxLoss, self).forward(pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "def bleu(pred_seq, label_seq, k):\n",
    "    \"\"\"\n",
    "    ËÆ°ÁÆó BLEU Score\n",
    "    \"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(\" \"), label_seq.split(\" \")\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[\" \".join(label_tokens[i:i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[\" \".join(pred_tokens[i:i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[\" \".join(pred_tokens[i:i + n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "def train(net, train_iter, lr, num_epochs, src_vocab, tgt_vocab, device, num_steps,Go=False,samples=None):\n",
    "    def init_weight(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    net.apply(init_weight)\n",
    "    net = net.to(device)\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxLoss()\n",
    "    net.train()\n",
    "    start_epoch=0\n",
    "    global L\n",
    "    if Go:\n",
    "        start_epoch,L=load_checkpoint(net, optim)\n",
    "        start_epoch+=1\n",
    "    if torch.cuda.device_count()>1:\n",
    "        net=nn.DataParallel(net)\n",
    "    for epoch in tqdm(range(start_epoch,num_epochs), desc=f\"<training>ü§´\"):\n",
    "        metric = Accumulator(2)\n",
    "        for batch in train_iter:\n",
    "            net.train()\n",
    "            optim.zero_grad()\n",
    "            X, X_valid_lens, y, y_valid_lens = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab[\"<bos>\"]] * y.shape[0], device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, y[:, :-1]], 1)\n",
    "            y_label=y\n",
    "            y_pred, _ = net(X, dec_input, X_valid_lens)\n",
    "            l = loss(y_pred, y_label, y_valid_lens)\n",
    "            l.sum().backward()\n",
    "            grad_clipping(net, 1)\n",
    "            optim.step()\n",
    "            with torch.no_grad():\n",
    "                num_tokens = y_valid_lens.sum()\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        temp=metric[0] / metric[1]\n",
    "        L.append(temp.cpu().numpy())\n",
    "        save_checkpoint(net, optim, epoch,L)\n",
    "        if epoch%10==0:\n",
    "            print(f\"Current Loss is {temp:.3f}\\n\")\n",
    "    Eval(num_epochs,net, src_vocab, tgt_vocab, num_steps, device,samples)\n",
    "\n",
    "# ‚úîÔ∏è\n",
    "def predict(net, src_sentence, src_vocab, tgt_vocab, num_steps, device):\n",
    "    net.eval()\n",
    "    model = net.module if hasattr(net, 'module') else net\n",
    "    encoder = model.encoder\n",
    "    decoder = model.decoder\n",
    "\n",
    "    # ÁºñÁ†ÅÂô®ÈÉ®ÂàÜ‰∏çÂèò\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = encoder(enc_X, enc_valid_len)\n",
    "    dec_state = decoder.init_state(enc_outputs, enc_valid_len)\n",
    "\n",
    "    dec_X = torch.tensor([[tgt_vocab['<bos>']]], device=device)\n",
    "    output_seq = []\n",
    "\n",
    "    for t in range(num_steps):           # t Â∞±ÊòØÂΩìÂâçÊ≠•ÁöÑ offset\n",
    "        Y, dec_state = decoder(dec_X, dec_state, offset=t)   # ÂÖ≥ÈîÆÔºÅ‰º† t\n",
    "        next_token = Y.argmax(dim=2)\n",
    "        pred = next_token.item()\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "        dec_X = next_token  # Teacher forcing offÔºåÁî®Ëá™Â∑±ÁöÑÈ¢ÑÊµã\n",
    "\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq))\n",
    "\n",
    "\n",
    "def Eval(num_epochs,net, src_vocab, tgt_vocab, num_steps, device,samples=None):\n",
    "    if not samples:\n",
    "        samples = [('go .', 'va !'),\n",
    "                 ('hi .', 'salut !'),\n",
    "                 ('run !', 'cours !'),\n",
    "                 ('hello .', 'bonjour .'),\n",
    "                 ('i won !', \"j'ai gagn√© !\"),\n",
    "                 (\"i'm ok .\", 'je vais bien .'),\n",
    "                 ('thank you .', 'merci .'),\n",
    "                 ('are you ok ?', '√ßa va ?'),\n",
    "                 (\"i'm home .\", 'je suis rentr√© .'),\n",
    "                 ('we won .', 'nous avons gagn√© .')]\n",
    "    metric=Accumulator(2)\n",
    "    for src,tgt in samples:\n",
    "        pred=predict(net, src, src_vocab, tgt_vocab, num_steps, device)\n",
    "        Single_bleu=bleu(pred,tgt,2)\n",
    "        print(f\"{pred:30}-------->,{tgt:30}\\t\\t{Single_bleu:.4f}\")\n",
    "        metric.add(1,Single_bleu)\n",
    "    print(f\"\\nOverall_score is {metric[1]/metric[0]:.4f}\")\n",
    "\n",
    "    # display\n",
    "    plt.plot(np.arange(1, num_epochs + 1), L, \"b-o\")\n",
    "    plt.title(\"Loss of epoches\")\n",
    "    plt.xlabel(\"Epoches\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(r\"./image/Loss.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T08:00:49.485094Z",
     "iopub.status.busy": "2025-11-20T08:00:49.484523Z",
     "iopub.status.idle": "2025-11-20T08:00:49.490229Z",
     "shell.execute_reply": "2025-11-20T08:00:49.489564Z",
     "shell.execute_reply.started": "2025-11-20T08:00:49.485069Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch,L, path=\"./storage/checkpoint.pt\"):\n",
    "    torch.save({\n",
    "        \"model\": model.module.state_dict() if torch.cuda.device_count()>1 else model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        'loss_history': L,\n",
    "    }, path)\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, path=\"./storage/checkpoint.pt\"):\n",
    "    print(\"loading...\")\n",
    "    checkpoint = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    print(f\"Resumed from epoch {checkpoint['epoch']} \")\n",
    "    return checkpoint[\"epoch\"],checkpoint[\"loss_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T04:53:04.421478Z",
     "iopub.status.busy": "2025-11-20T04:53:04.421180Z",
     "iopub.status.idle": "2025-11-20T04:53:04.429544Z",
     "shell.execute_reply": "2025-11-20T04:53:04.428797Z",
     "shell.execute_reply.started": "2025-11-20T04:53:04.421454Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import math\n",
    "\n",
    "#‚úîÔ∏è\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"ÁºñÁ†ÅÂùó\"\"\"\n",
    "    def __init__(self,key_size,query_size,value_size,num_hiddens,\n",
    "                norm_shape,ffn_num_inputs,ffn_num_hiddens,\n",
    "                num_heads,dropout,use_bias=False,**kwargs):\n",
    "        super(EncoderBlock,self).__init__(**kwargs)\n",
    "        self.attention=MultiHeadAttention(key_size,query_size,value_size,num_hiddens,num_heads,dropout,use_bias)\n",
    "        self.addnorm1=AddNorm(norm_shape,dropout)\n",
    "        self.ffn=FFN(ffn_num_inputs,ffn_num_hiddens,num_hiddens)\n",
    "        self.addnorm2=AddNorm(norm_shape,dropout)\n",
    "\n",
    "    def forward(self,X,valid_lens):\n",
    "        # Ë¶ÅÊ±Ç key_size==num_hiddens\n",
    "        y=self.addnorm1(X,self.attention(X,X,X,valid_lens))\n",
    "        # <output>shape: (batch,query_num,num_hiddens)\n",
    "        return self.addnorm2(y,self.ffn(y))\n",
    "\n",
    "#‚úîÔ∏è\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"Encoer( core )ü§´\"\"\"\n",
    "    def __init__(self,vocab_size,key_size,query_size,value_size,num_hiddens,\n",
    "                norm_shape,ffn_num_inputs,ffn_num_hiddens,num_heads,num_layers,dropout,use_bias=False,**kwargs):\n",
    "        super(TransformerEncoder,self).__init__(**kwargs)\n",
    "        self.num_hiddens=num_hiddens\n",
    "        self.embedding=nn.Embedding(vocab_size,num_hiddens)\n",
    "        self.pos_encoding=PositionalEncoding(num_hiddens,dropout)\n",
    "        self.blks=nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(f\"block_{i}\",EncoderBlock(key_size,query_size,value_size,num_hiddens,\n",
    "                                                          norm_shape,ffn_num_inputs,ffn_num_hiddens,num_heads,\n",
    "                                                          dropout,use_bias))\n",
    "\n",
    "    def forward(self,X,valid_lens,*args):\n",
    "        # Èò≤Ê≠¢ËæìÂÖ•‰ø°Âè∑Áî±È°∫Â∫è‰ø°Âè∑Âç†‰∏ªÂØºÔºåÂØºËá¥Âô™Â£∞ÁâπÂà´Â§ßÊó†Ê≥ïËÆ≠ÁªÉ\n",
    "        X=self.pos_encoding(self.embedding(X)*math.sqrt(self.num_hiddens))\n",
    "        for blk in self.blks:\n",
    "            X=blk(X,valid_lens)\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T04:53:04.600306Z",
     "iopub.status.busy": "2025-11-20T04:53:04.599704Z",
     "iopub.status.idle": "2025-11-20T04:53:04.610291Z",
     "shell.execute_reply": "2025-11-20T04:53:04.609652Z",
     "shell.execute_reply.started": "2025-11-20T04:53:04.600284Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "#‚úîÔ∏è\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"Ëß£Á†ÅÂô®Âùó\"\"\"\n",
    "\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "                 ffn_num_inputs, ffn_num_hiddens, num_heads, dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = FFN(ffn_num_inputs, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        \"\"\"Ëß£Á†ÅÂô®ÈúÄË¶ÅÁºñÁ†ÅÂô®ÊèêÂèñÁöÑÂÖ®Â±ÄÁâπÂæÅstate‰ª•ÂèäÂΩìÂâçËæìÂÖ•ÁâπÂæÅ\"\"\"\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat([state[2][self.i], X], axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        # trainingÂ±ûÊÄßÊòØnn.ModuleËá™Âä®Áª¥Êä§ÁöÑÔºåÂΩì‰Ω†shezhiModel.train()ÁöÑÊó∂ÂÄôËØ•Â±ûÊÄßÂ∞±‰ºöË¢´Ëá™Âä®ËÆæÁΩÆ‰∏∫True\n",
    "        # module.training = True\n",
    "        if self.training:\n",
    "            # ÁîüÊàê mask Êé©Á†ÅÔºåÁî®‰∫éËÆ≠ÁªÉÁöÑÊó∂ÂÄôÈÅÆËîΩÂêéÈù¢ÁöÑËØçÂÖÉ\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            dec_valid_lens = torch.arange(1, num_steps+ 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "        # Âú®ËøôÈáåÔºåX‰Ωú‰∏∫ query Ôºåkey_values‰Ωú‰∏∫ÈîÆÂÄºÂØπÔºåË°®Á§∫ key_valuesÁöÑÊØè‰∏™‰ΩçÁΩÆÂØπÂΩìÂâçÊü•ËØ¢ÁöÑÂΩ±ÂìçÊùÉÈáç\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        y = self.addnorm1(X, X2)\n",
    "        # enc_outputs shape:(batch,query_num,num_hiddens)\n",
    "        y2 = self.attention2(y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(y, y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state\n",
    "\n",
    "#‚úîÔ∏è\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self,vocab_size,key_size,query_size,value_size,num_hiddens,norm_shape,\\\n",
    "                ffn_num_inputs,ffn_num_hiddens,num_heads,num_layers,dropout,**kwargs):\n",
    "        super(TransformerDecoder,self).__init__(**kwargs)\n",
    "        self.num_hiddens=num_hiddens\n",
    "        self.num_layers=num_layers\n",
    "        self.embedding=nn.Embedding(vocab_size,num_hiddens)\n",
    "        self.pos_encoding=PositionalEncoding(num_hiddens,dropout)\n",
    "        self.blks=nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(f\"block_{i}\",DecoderBlock(key_size,query_size,value_size,num_hiddens,\\\n",
    "                                                           norm_shape, ffn_num_inputs,ffn_num_hiddens,\\\n",
    "                                                           num_heads,dropout,i))\n",
    "        self.dense=nn.Linear(num_hiddens,vocab_size)\n",
    "\n",
    "    def init_state(self,enc_outputs,enc_valid_lens,*args):\n",
    "        return [enc_outputs,enc_valid_lens,[None]*self.num_layers]\n",
    "    \n",
    "    def forward(self, X, state, offset=0):   # Êñ∞Â¢û offset ÂèÇÊï∞\n",
    "            X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens), offset)\n",
    "            for i, blk in enumerate(self.blks):\n",
    "                X, state = blk(X, state)\n",
    "            return self.dense(X), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T04:53:04.720693Z",
     "iopub.status.busy": "2025-11-20T04:53:04.720514Z",
     "iopub.status.idle": "2025-11-20T04:53:04.734982Z",
     "shell.execute_reply": "2025-11-20T04:53:04.734349Z",
     "shell.execute_reply.started": "2025-11-20T04:53:04.720680Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def read_data():\n",
    "    \"\"\"ËΩΩÂÖ•‚ÄúËã±ËØ≠ÔºçÊ≥ïËØ≠‚ÄùÊï∞ÊçÆÈõÜ\"\"\"\n",
    "    data_dir = \"../data/fra-eng\"\n",
    "    with open(os.path.join(data_dir, 'fra.txt'), 'r',\n",
    "              encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def preprocess(text):\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?‚Äû‚Äú;:') and prev_char != ' '\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    # Âú®ÂçïËØçÂíåÊ†áÁÇπÁ¨¶Âè∑‰πãÈó¥ÊèíÂÖ•Á©∫Ê†º\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "           for i, char in enumerate(text)]\n",
    "    return ''.join(out)\n",
    "\n",
    "def tokenize(text, num_examples=None):\n",
    "    \"\"\"ËØçÂÖÉÂåñ‚ÄúËã±ËØ≠ÔºçÊ≥ïËØ≠‚ÄùÊï∞ÊçÆÊï∞ÊçÆÈõÜ\"\"\"\n",
    "    source, target = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples:\n",
    "            break\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts)>=2:\n",
    "            source.append(parts[0].lower().split(' '))\n",
    "            target.append(parts[1].lower().split(' '))\n",
    "    return source, target\n",
    "\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"Âª∫Á´ãËØçË°®\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        counter = self.count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "        self.idx_to_token = [\"<unk>\"] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        \"\"\"token->idx\"\"\"\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        \"\"\"idx->token\"\"\"\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "\n",
    "    def count_corpus(self, tokens):\n",
    "        \"\"\"ÁªüËÆ°ËØçÂÖÉÈ¢ëÁéá\"\"\"\n",
    "        if len(tokens)==0 or isinstance(tokens[0], list):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        # tokensÂ∫îËØ•ÊòØ‰∏Ä‰∏™ÂàóË°®ÂΩ¢Âºè\n",
    "        return Counter(tokens)\n",
    "\n",
    "def load_array(src_vocab,tgt_vocab,src,tgt,batch_size,num_steps,is_train=True):\n",
    "    def build_array(lines, vocab, num_steps):\n",
    "        lines = [vocab[l] for l in lines]\n",
    "        lines = [l + [vocab['<eos>']] for l in lines]\n",
    "        array = torch.tensor([\n",
    "            truncate_pad(l, num_steps, vocab['<pad>']) for l in lines\n",
    "        ])  # shape: (N, num_steps)\n",
    "\n",
    "        valid_lens = (array != vocab['<pad>']).sum(1)\n",
    "        return array, valid_lens\n",
    "\n",
    "\n",
    "    def truncate_pad(line,num_steps,padding_token):\n",
    "        \"\"\"Êà™Êñ≠ÊàñËÄÖÂ°´ÂÖÖÂ∫èÂàóÔºå‰ª•‰øùËØÅÂ∫èÂàóÈïøÂ∫¶‰∏ÄËá¥\"\"\"\n",
    "        if len(line)>num_steps:\n",
    "            return line[:num_steps]\n",
    "        return line+[padding_token]*(num_steps-len(line))\n",
    "\n",
    "    # ÂØºÂÖ•\n",
    "    src_array,src_valid_lens=build_array(src,src_vocab,num_steps)\n",
    "    tgt_array,tgt_valid_lens=build_array(tgt,tgt_vocab,num_steps)\n",
    "    data_arrays=(src_array,src_valid_lens,tgt_array,tgt_valid_lens)\n",
    "\n",
    "    return DataLoader(TensorDataset(*data_arrays),batch_size,shuffle=is_train)\n",
    "\n",
    "def load_data(batch_size, num_steps, num_examples=None):\n",
    "    \"\"\"\n",
    "    :param batch_size:\n",
    "    :param num_steps:\n",
    "    :param num_examples:\n",
    "    :return: train_iter,test_iter,val_iter,src_vocab,tgt_vocab\n",
    "    \"\"\"\n",
    "    text = read_data()\n",
    "    train_src, train_tgt = tokenize(preprocess(text),num_examples)\n",
    "\n",
    "    # Âª∫Á´ãËØçË°®ÔºåÊé•‰∏ãÊù•Â∫îËØ•ËΩ¨Êç¢ËØçÂÖÉ\n",
    "    src_vocab = Vocab(train_src, min_freq=2, reserved_tokens=[\"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "    tgt_vocab = Vocab(train_tgt, min_freq=2, reserved_tokens=[\"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "\n",
    "    train_iter = load_array(src_vocab, tgt_vocab, train_src, train_tgt, batch_size, num_steps, True)\n",
    "    return train_iter,src_vocab,tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T04:53:10.377955Z",
     "iopub.status.busy": "2025-11-20T04:53:10.377695Z",
     "iopub.status.idle": "2025-11-20T04:53:10.382120Z",
     "shell.execute_reply": "2025-11-20T04:53:10.381395Z",
     "shell.execute_reply.started": "2025-11-20T04:53:10.377935Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"./storage\",exist_ok=True)\n",
    "os.makedirs(\"./image\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T08:01:21.510493Z",
     "iopub.status.busy": "2025-11-20T08:01:21.510193Z",
     "iopub.status.idle": "2025-11-20T08:01:33.551371Z",
     "shell.execute_reply": "2025-11-20T08:01:33.550595Z",
     "shell.execute_reply.started": "2025-11-20T08:01:21.510471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n",
      "Resumed from epoch 99 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<training>ü§´: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allez-y .                     -------->,va !                          \t\t0.0000\n",
      "salut !                       -------->,salut !                       \t\t1.0000\n",
      "cours !                       -------->,cours !                       \t\t1.0000\n",
      "salut !                       -------->,bonjour .                     \t\t0.0000\n",
      "j'ai gagn√© !                  -------->,j'ai gagn√© !                  \t\t1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "je vais bien .                -------->,je vais bien .                \t\t1.0000\n",
      "merci .                       -------->,merci .                       \t\t1.0000\n",
      "vous vous allez bien ?        -------->,√ßa va ?                       \t\t0.0000\n",
      "je suis chez moi .            -------->,je suis rentr√© .              \t\t0.5477\n",
      "nous avons gagn√© .            -------->,nous avons gagn√© .            \t\t1.0000\n",
      "\n",
      "Overall_score is 0.6548\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # < ËÆ≠ÁªÉ > (‰∏ªÂáΩÊï∞)\n",
    "    L=[]\n",
    "    num_hiddens, num_layers, dropout, batch_size, num_steps = 128, 4, 0.1, 128, 20\n",
    "    lr, num_epochs, device = 0.0005, 100, \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    ffn_num_inputs, ffn_num_hiddens, num_heads = 128, 256, 8\n",
    "    key_size, query_size, value_size = 128, 128, 128\n",
    "    norm_shape = [128]\n",
    "    samples=None\n",
    "    train_iter,src_vocab, tgt_vocab = load_data(batch_size, num_steps)\n",
    "    encoder = TransformerEncoder(len(src_vocab), key_size, query_size, value_size, num_hiddens, norm_shape, \\\n",
    "                                 ffn_num_inputs, ffn_num_hiddens, num_heads, num_layers, dropout)\n",
    "    decoder = TransformerDecoder(len(tgt_vocab), key_size, query_size, value_size, num_hiddens, norm_shape, \\\n",
    "                                 ffn_num_inputs, ffn_num_hiddens, num_heads, num_layers, dropout)\n",
    "            \n",
    "    net = EncoderDecoder(encoder, decoder)\n",
    "    train(net, train_iter, lr, num_epochs,  src_vocab,tgt_vocab, device,num_steps,Go=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8767760,
     "sourceId": 13775430,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
